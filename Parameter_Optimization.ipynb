{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "de4es17w1D8-",
        "outputId": "c4f92815-3158-45f5-cbc2-b400472abe6b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.15.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.5.0)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.58.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "# Install necessary packages\n",
        "!pip install scikit-learn pandas matplotlib\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import svm\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "import random\n",
        "import urllib.request\n",
        "\n",
        "# Step 1: Download and Load UCI Letter Recognition Dataset\n",
        "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/letter-recognition/letter-recognition.data\"\n",
        "file_name = \"letter-recognition.data\"\n",
        "urllib.request.urlretrieve(url, file_name)\n",
        "\n",
        "# Step 2: Load the dataset into pandas\n",
        "column_names = ['letter', 'x-box', 'y-box', 'width', 'high', 'onpix', 'x-bar',\n",
        "                'y-bar', 'x2bar', 'y2bar', 'xybar', 'x2ybr', 'xy2br', 'x-ege',\n",
        "                'xegvy', 'y-ege', 'yegvx']\n",
        "df = pd.read_csv(file_name, header=None, names=column_names)\n",
        "\n",
        "# Step 3: Preprocess data\n",
        "X = df.iloc[:, 1:].values  # Features\n",
        "y = df.iloc[:, 0].values   # Labels\n",
        "\n",
        "# Encode labels\n",
        "le = LabelEncoder()\n",
        "y = le.fit_transform(y)\n",
        "\n",
        "# Normalize features\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "\n",
        "# Step 4: Define parameter search space\n",
        "kernels = ['linear', 'poly', 'rbf', 'sigmoid']\n",
        "nu_vals = np.linspace(0.01, 0.9, 10)\n",
        "eps_vals = np.linspace(0.001, 0.2, 10)\n",
        "\n",
        "results = []\n",
        "convergence_all = []\n",
        "\n",
        "# Step 5: Loop over 10 random samples\n",
        "for sample_id in range(10):\n",
        "    # Train/test split\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X, y, test_size=0.3, stratify=y, random_state=sample_id\n",
        "    )\n",
        "\n",
        "    best_accuracy = 0\n",
        "    best_params = {}\n",
        "    convergence = []\n",
        "\n",
        "    for i in range(100):\n",
        "        kernel = random.choice(kernels)\n",
        "        nu = round(random.choice(nu_vals), 3)\n",
        "        epsilon = round(random.choice(eps_vals), 3)\n",
        "\n",
        "        try:\n",
        "            clf = svm.NuSVC(kernel=kernel, nu=nu)\n",
        "            clf.fit(X_train, y_train)\n",
        "            y_pred = clf.predict(X_test)\n",
        "            acc = accuracy_score(y_test, y_pred)\n",
        "\n",
        "            convergence.append(acc)\n",
        "\n",
        "            if acc > best_accuracy:\n",
        "                best_accuracy = acc\n",
        "                best_params = {'kernel': kernel, 'nu': nu, 'epsilon': epsilon}\n",
        "        except:\n",
        "            convergence.append(best_accuracy)\n",
        "            continue\n",
        "\n",
        "    results.append((sample_id + 1, best_accuracy, best_params))\n",
        "    convergence_all.append(convergence)\n",
        "\n",
        "# Step 6: Print Results Table\n",
        "print(\"\\nSample\\tAccuracy\\tKernel\\tNu\\tEpsilon\")\n",
        "for i, acc, params in results:\n",
        "    print(f\"S{i}\\t{acc:.4f}\\t{params['kernel']}\\t{params['nu']}\\t{params['epsilon']}\")\n",
        "\n",
        "# Step 7: Plot convergence graph for the best-performing sample\n",
        "best_sample_idx = np.argmax([acc for _, acc, _ in results])\n",
        "best_convergence = convergence_all[best_sample_idx]\n",
        "\n",
        "plt.figure(figsize=(8,5))\n",
        "plt.plot(best_convergence, color='blue')\n",
        "plt.title('Fitness (bestAccuracy)')\n",
        "plt.xlabel('Iteration')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2DDvdeJY1F4Y"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}